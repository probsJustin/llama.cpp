version: '3.8'

services:
  # Jaeger all-in-one for tracing visualization
  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "16686:16686"  # UI
      - "14250:14250"  # gRPC collector
      - "14268:14268"  # HTTP collector
      - "4317:4317"    # OTLP gRPC receiver
      - "4318:4318"    # OTLP HTTP receiver
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    networks:
      - llama-observability

  # llama.cpp server with OpenTelemetry instrumentation
  llama-cpp-server:
    build:
      context: ../..
      dockerfile: ./observability/dockerfiles/Dockerfile.standalone
    ports:
      - "8080:8080"   # Server API endpoint
    volumes:
      - ../../models:/app/models
    environment:
      - OTEL_SERVICE_NAME=llama-cpp-server
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://jaeger:4317
      - OTEL_RESOURCE_ATTRIBUTES=service.name=llama-cpp-server,service.version=1.0.0
      - OTEL_TRACES_SAMPLER=always_on
      - OTEL_METRICS_EXPORTER=otlp
      - OTEL_LOGS_EXPORTER=otlp
    command: ["-m", "/app/models/7B/ggml-model-q4_0.gguf", "--host", "0.0.0.0", "--port", "8080"]
    networks:
      - llama-observability
    depends_on:
      - jaeger

networks:
  llama-observability:
    driver: bridge